{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH_TO_DATA = ('D:/Py/DataFrames/Santander_Value_Prediction_Challenge(KAGGLE)/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and joining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target length: 4459\n"
     ]
    }
   ],
   "source": [
    "y = pd.read_csv(os.path.join(PATH_TO_DATA, 'input/train.csv'), usecols=['target'])\n",
    "y = np.log1p(y.target.values)\n",
    "print('Target length:', len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 33.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df_statistic_and_bin = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_with_row_statistic_and_bin_thresh098.csv'))\n",
    "test_df_statistic_and_bin = pd.read_csv(os.path.join(PATH_TO_DATA, 'test_with_row_statistic_and_bin_thresh098.csv'))\n",
    "\n",
    "train_space_reduction = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_space_reduction_thresh098.csv'))\n",
    "test_space_reduction = pd.read_csv(os.path.join(PATH_TO_DATA, 'test_space_reduction_thresh098.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop 600 columns\n"
     ]
    }
   ],
   "source": [
    "# Use only FA and SRP features\n",
    "cols_to_drop = [x for x in train_space_reduction.columns if str(x)[:2] not in ['fa', 'sr']]\n",
    "print('Drop', len(cols_to_drop), 'columns')\n",
    "train_space_reduction = train_space_reduction.drop(cols_to_drop, axis=1, inplace=True)\n",
    "test_space_reduction = test_space_reduction.drop(cols_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (4459, 3370)\n",
      "Test: (49342, 3370)\n",
      "Wall time: 888 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df = pd.concat([train_df_statistic_and_bin, train_space_reduction], axis=1)\n",
    "test_df = pd.concat([test_df_statistic_and_bin, test_space_reduction], axis=1)\n",
    "\n",
    "del train_df_statistic_and_bin, test_df_statistic_and_bin\n",
    "del train_space_reduction, test_space_reduction\n",
    "gc.collect()\n",
    "\n",
    "print('Train:', train_df.shape)\n",
    "print('Test:', test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost + LightGBM + CV Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_xgb(train_X, train_y, val_X, val_y, test_X):\n",
    "    params = {\n",
    "        'objective': 'reg:linear',\n",
    "        'booster': 'gbtree',\n",
    "        'metric': 'rmse',\n",
    "        'learning_rate': 0.005,\n",
    "        'max_depth': 8,\n",
    "        'subsample': 0.7,\n",
    "        'colsample_bytree': 0.1,\n",
    "        'alpha':0,\n",
    "        'lambda': 0,\n",
    "        'gamma': 1.5,\n",
    "        'silent': True,\n",
    "        'random_state': 44,\n",
    "        'nthread': -1\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "    xgval = xgb.DMatrix(val_X, label=val_y)\n",
    "    xgtest = xgb.DMatrix(test_X)\n",
    "    watchlist = [(xgtrain, 'train'), (xgval, 'valid')]\n",
    "    model = xgb.train(params, xgtrain, 2000, watchlist, \n",
    "                      early_stopping_rounds=50, \n",
    "                      verbose_eval=100)\n",
    "    print('Model training done in {} seconds.'.format(time.time() - start_time))\n",
    "    \n",
    "    pred_test_y = np.expm1(model.predict(xgtest, ntree_limit=model.best_ntree_limit))\n",
    "    pred_oof_log = model.predict(xgval, ntree_limit=model.best_ntree_limit)\n",
    "    return pred_test_y, pred_oof_log, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_lgb(train_X, train_y, val_X, val_y, test_X):\n",
    "    params = {\n",
    "        \"objective\" : \"regression\",\n",
    "        \"metric\" : \"rmse\",\n",
    "        \"num_leaves\" : 40,\n",
    "        'max_depth': 8,\n",
    "        \"learning_rate\" : 0.005,\n",
    "        \"bagging_fraction\" : 0.7,\n",
    "        \"feature_fraction\" : 0.1, #0.6,\n",
    "        \"bagging_frequency\" : 6,\n",
    "        \"bagging_seed\" : 44,\n",
    "        \"verbosity\" : -1,\n",
    "        'num_threads' : 4,\n",
    "        \"seed\": 44\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    lgtrain = lgb.Dataset(train_X, label=train_y)\n",
    "    lgval = lgb.Dataset(val_X, label=val_y)\n",
    "    model = lgb.train(params, lgtrain, 5000, \n",
    "                      valid_sets=[lgtrain, lgval], \n",
    "                      early_stopping_rounds=100, \n",
    "                      verbose_eval=150)\n",
    "    print('Model training done in {} seconds.'.format(time.time() - start_time))\n",
    "    \n",
    "    pred_test_y = np.expm1(model.predict(test_X, num_iteration=model.best_iteration))\n",
    "    pred_oof_log = model.predict(val_X, num_iteration=model.best_iteration)\n",
    "    \n",
    "    return pred_test_y, pred_oof_log, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_calculations(X, test, func_name = None):\n",
    "    if not func_name:\n",
    "        return print('The function to run is not defined')\n",
    "    else:\n",
    "        n_splits = 5\n",
    "        random_state = 44\n",
    "\n",
    "        y_oof = np.zeros((y.shape[0]))\n",
    "        fold_errors =[]\n",
    "        pred_test_list = []\n",
    "        \n",
    "\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "        for i, (train_index, val_index) in enumerate(kf.split(y)):\n",
    "            print('Fitting fold', i+1, 'out of', n_splits)\n",
    "            X_train, X_val  = X.iloc[train_index], X.iloc[val_index]\n",
    "            y_train, y_val = y[train_index], y[val_index]\n",
    "            if func_name == 'lgb':\n",
    "                pred_test_y, pred_oof_log, clf = run_lgb(X_train, y_train, X_val, y_val, test)\n",
    "            elif func_name == 'xgb':\n",
    "                pred_test_y, pred_oof_log, clf = run_xgb(X_train, y_train, X_val, y_val, test)\n",
    "            elif func_name == 'cat':\n",
    "                pred_test_y, pred_oof_log, clf = run_cat(X_train, y_train, X_val, y_val, test)\n",
    "            else:\n",
    "                return print('The function to run is not correct')\n",
    "                \n",
    "            y_oof[val_index] = pred_oof_log\n",
    "            curr_fe = np.sqrt(mean_squared_error(y_val, pred_oof_log))\n",
    "            print(f'Fold error {curr_fe}')\n",
    "            fold_errors.append(curr_fe)\n",
    "            pred_test_list.append(list(pred_test_y))\n",
    "            \n",
    "        print('Total error', np.sqrt(mean_squared_error(y, y_oof)))\n",
    "        total_fe_std = round(np.std(fold_errors), 5)\n",
    "        print(f'Total std {total_fe_std}')\n",
    "        avg_test_pred = np.mean(pred_test_list, axis=0)\n",
    "        \n",
    "        return y_oof, avg_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting fold 1 out of 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[150]\ttraining's rmse: 1.42978\tvalid_1's rmse: 1.43401\n",
      "[300]\ttraining's rmse: 1.27366\tvalid_1's rmse: 1.33583\n",
      "[450]\ttraining's rmse: 1.18603\tvalid_1's rmse: 1.30047\n",
      "[600]\ttraining's rmse: 1.1261\tvalid_1's rmse: 1.28624\n",
      "[750]\ttraining's rmse: 1.08592\tvalid_1's rmse: 1.28166\n",
      "[900]\ttraining's rmse: 1.05535\tvalid_1's rmse: 1.28031\n",
      "[1050]\ttraining's rmse: 1.03167\tvalid_1's rmse: 1.28086\n",
      "Early stopping, best iteration is:\n",
      "[957]\ttraining's rmse: 1.04527\tvalid_1's rmse: 1.28005\n",
      "Model training done in 28.302698373794556 seconds.\n",
      "Fold error 1.280050628941497\n",
      "Fitting fold 2 out of 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[150]\ttraining's rmse: 1.41304\tvalid_1's rmse: 1.49962\n",
      "[300]\ttraining's rmse: 1.25608\tvalid_1's rmse: 1.41352\n",
      "[450]\ttraining's rmse: 1.17101\tvalid_1's rmse: 1.38379\n",
      "[600]\ttraining's rmse: 1.11253\tvalid_1's rmse: 1.373\n",
      "[750]\ttraining's rmse: 1.07265\tvalid_1's rmse: 1.36959\n",
      "[900]\ttraining's rmse: 1.04057\tvalid_1's rmse: 1.36753\n",
      "[1050]\ttraining's rmse: 1.01644\tvalid_1's rmse: 1.3669\n",
      "Early stopping, best iteration is:\n",
      "[1037]\ttraining's rmse: 1.01863\tvalid_1's rmse: 1.36669\n",
      "Model training done in 29.188570499420166 seconds.\n",
      "Fold error 1.366687256254748\n",
      "Fitting fold 3 out of 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[150]\ttraining's rmse: 1.42262\tvalid_1's rmse: 1.4654\n",
      "[300]\ttraining's rmse: 1.2676\tvalid_1's rmse: 1.36279\n",
      "[450]\ttraining's rmse: 1.18051\tvalid_1's rmse: 1.32802\n",
      "[600]\ttraining's rmse: 1.12123\tvalid_1's rmse: 1.31615\n",
      "[750]\ttraining's rmse: 1.0802\tvalid_1's rmse: 1.31259\n",
      "[900]\ttraining's rmse: 1.04844\tvalid_1's rmse: 1.31214\n",
      "Early stopping, best iteration is:\n",
      "[847]\ttraining's rmse: 1.05822\tvalid_1's rmse: 1.31178\n",
      "Model training done in 26.37443709373474 seconds.\n",
      "Fold error 1.311776619828437\n",
      "Fitting fold 4 out of 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[150]\ttraining's rmse: 1.41415\tvalid_1's rmse: 1.51199\n",
      "[300]\ttraining's rmse: 1.25985\tvalid_1's rmse: 1.41562\n",
      "[450]\ttraining's rmse: 1.17535\tvalid_1's rmse: 1.378\n",
      "[600]\ttraining's rmse: 1.11728\tvalid_1's rmse: 1.36148\n",
      "[750]\ttraining's rmse: 1.07692\tvalid_1's rmse: 1.35355\n",
      "[900]\ttraining's rmse: 1.04686\tvalid_1's rmse: 1.35037\n",
      "[1050]\ttraining's rmse: 1.02472\tvalid_1's rmse: 1.34934\n",
      "[1200]\ttraining's rmse: 1.00516\tvalid_1's rmse: 1.34868\n",
      "[1350]\ttraining's rmse: 0.987477\tvalid_1's rmse: 1.34819\n",
      "Early stopping, best iteration is:\n",
      "[1339]\ttraining's rmse: 0.988845\tvalid_1's rmse: 1.34816\n",
      "Model training done in 34.222246408462524 seconds.\n",
      "Fold error 1.3481641616497466\n",
      "Fitting fold 5 out of 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[150]\ttraining's rmse: 1.40899\tvalid_1's rmse: 1.52063\n",
      "[300]\ttraining's rmse: 1.25198\tvalid_1's rmse: 1.43357\n",
      "[450]\ttraining's rmse: 1.1661\tvalid_1's rmse: 1.40474\n",
      "[600]\ttraining's rmse: 1.10776\tvalid_1's rmse: 1.39499\n",
      "[750]\ttraining's rmse: 1.06775\tvalid_1's rmse: 1.39244\n",
      "[900]\ttraining's rmse: 1.03582\tvalid_1's rmse: 1.39117\n",
      "Early stopping, best iteration is:\n",
      "[936]\ttraining's rmse: 1.02966\tvalid_1's rmse: 1.39088\n",
      "Model training done in 27.59854817390442 seconds.\n",
      "Fold error 1.3908809866033558\n",
      "Total error 1.34007929316\n",
      "Total std 0.03939\n",
      "Wall time: 3min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_oof_lgb, pred_test_list_lgb = run_calculations(train_df, test_df, 'lgb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
